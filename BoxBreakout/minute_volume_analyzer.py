#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
åˆ†é’Ÿçº§é‡æ¯”åˆ†æå™¨
åŸºäºbaostockåˆ†é’ŸKçº¿æ•°æ®è®¡ç®—é‡æ¯”ç‰¹å¾ï¼Œä½œä¸ºåˆ†æ—¶é‡æ¯”çš„æ›¿ä»£æ–¹æ¡ˆ
"""

import baostock as bs
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from typing import Dict, List, Tuple, Optional
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
plt.rcParams['axes.unicode_minus'] = False

class MinuteVolumeAnalyzer:
    """
    åˆ†é’Ÿçº§é‡æ¯”åˆ†æå™¨
    åŸºäºåˆ†é’ŸKçº¿æ•°æ®è®¡ç®—é‡æ¯”ç‰¹å¾ï¼Œæ¨¡æ‹Ÿåˆ†æ—¶é‡æ¯”æ•ˆæœ
    """
    
    def __init__(self, stock_code: str):
        self.stock_code = stock_code
        self.minute_data = None
        self.daily_data = None
        
    def fetch_minute_data(self, start_date: str, end_date: str, frequency: str = "5"):
        """
        è·å–åˆ†é’Ÿçº§Kçº¿æ•°æ®
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸ "YYYY-MM-DD"
            end_date: ç»“æŸæ—¥æœŸ "YYYY-MM-DD" 
            frequency: åˆ†é’Ÿçº§åˆ« "5", "15", "30", "60"
        """
        lg = bs.login()
        if lg.error_code != '0':
            print(f"ç™»å½•å¤±è´¥: {lg.error_msg}")
            return None
            
        print(f"è·å– {self.stock_code} {frequency}åˆ†é’ŸKçº¿æ•°æ®...")
        
        rs = bs.query_history_k_data_plus(
            self.stock_code,
            "date,time,code,open,high,low,close,volume,amount,adjustflag",
            start_date=start_date,
            end_date=end_date,
            frequency=frequency,
            adjustflag="3"
        )
        
        if rs.error_code != '0':
            print(f"æŸ¥è¯¢å¤±è´¥: {rs.error_msg}")
            bs.logout()
            return None
            
        data_list = []
        while rs.next():
            data_list.append(rs.get_row_data())
            
        bs.logout()
        
        if not data_list:
            print("æœªè·å–åˆ°åˆ†é’Ÿæ•°æ®")
            return None
            
        df = pd.DataFrame(data_list, columns=rs.fields)
        
        # æ•°æ®ç±»å‹è½¬æ¢
        for col in ['open', 'high', 'low', 'close', 'volume', 'amount']:
            df[col] = pd.to_numeric(df[col], errors='coerce')
            
        # å¤„ç†baostockç‰¹æ®Šçš„æ—¶é—´æ ¼å¼
        # baostockåˆ†é’Ÿæ•°æ®çš„timeæ ¼å¼å¯èƒ½æ˜¯ "20241101093500000"
        def parse_baostock_time(date_str, time_str):
            try:
                if len(time_str) >= 14:  # æ ¼å¼: 20241101093500000
                    # æå–æ—¥æœŸå’Œæ—¶é—´éƒ¨åˆ†
                    date_part = time_str[:8]  # 20241101
                    time_part = time_str[8:14]  # 093500
                    
                    # æ ¼å¼åŒ–ä¸ºæ ‡å‡†æ—¶é—´
                    formatted_date = f"{date_part[:4]}-{date_part[4:6]}-{date_part[6:8]}"
                    formatted_time = f"{time_part[:2]}:{time_part[2:4]}:{time_part[4:6]}"
                    
                    return pd.to_datetime(f"{formatted_date} {formatted_time}")
                else:
                    # å¦‚æœæ˜¯æ ‡å‡†æ ¼å¼ï¼Œç›´æ¥è§£æ
                    return pd.to_datetime(f"{date_str} {time_str}")
            except:
                return pd.NaT
        
        # åˆ›å»ºå®Œæ•´çš„datetimeåˆ—
        df['datetime'] = df.apply(lambda row: parse_baostock_time(row['date'], row['time']), axis=1)
        df['date'] = pd.to_datetime(df['date'])
        
        # ä»datetimeä¸­æå–æ ‡å‡†æ—¶é—´æ ¼å¼
        df['time'] = df['datetime'].dt.strftime('%H:%M:%S')
        
        df = df.dropna()
        df.reset_index(drop=True, inplace=True)
        
        self.minute_data = df
        print(f"æˆåŠŸè·å– {len(df)} æ¡åˆ†é’Ÿæ•°æ®")
        return df
        
    def fetch_daily_data(self, start_date: str, end_date: str):
        """è·å–æ—¥çº¿æ•°æ®ç”¨äºè®¡ç®—åŸºå‡†é‡æ¯”"""
        lg = bs.login()
        if lg.error_code != '0':
            print(f"ç™»å½•å¤±è´¥: {lg.error_msg}")
            return None
            
        rs = bs.query_history_k_data_plus(
            self.stock_code,
            "date,open,high,low,close,volume,amount,turn",
            start_date=start_date,
            end_date=end_date,
            frequency="d",
            adjustflag="3"
        )
        
        data_list = []
        while rs.next():
            data_list.append(rs.get_row_data())
            
        bs.logout()
        
        if not data_list:
            return None
            
        df = pd.DataFrame(data_list, columns=rs.fields)
        df['date'] = pd.to_datetime(df['date'])
        for col in ['open', 'high', 'low', 'close', 'volume', 'amount', 'turn']:
            df[col] = pd.to_numeric(df[col], errors='coerce')
            
        df = df.dropna()
        self.daily_data = df
        return df
        
    def calculate_volume_ratio_features(self) -> Dict:
        """
        è®¡ç®—åŸºäºåˆ†é’Ÿæ•°æ®çš„é‡æ¯”ç‰¹å¾
        
        Returns:
            åŒ…å«å„ç§é‡æ¯”ç‰¹å¾çš„å­—å…¸
        """
        if self.minute_data is None or self.daily_data is None:
            print("è¯·å…ˆè·å–åˆ†é’Ÿå’Œæ—¥çº¿æ•°æ®")
            return {}
            
        minute_df = self.minute_data.copy()
        daily_df = self.daily_data.copy()
        
        # æŒ‰æ—¥æœŸåˆ†ç»„è®¡ç®—é‡æ¯”ç‰¹å¾
        features = {
            'opening_volume_ratio': [],  # å¼€ç›˜é‡æ¯”
            'intraday_volume_patterns': [],  # æ—¥å†…é‡æ¯”æ¨¡å¼
            'volume_surge_times': [],  # æ”¾é‡æ—¶ç‚¹
            'daily_volume_distribution': []  # æ—¥å†…æˆäº¤é‡åˆ†å¸ƒ
        }
        
        # è®¡ç®—å†å²å¹³å‡æˆäº¤é‡ï¼ˆç”¨äºé‡æ¯”åŸºå‡†ï¼‰
        daily_df['volume_ma5'] = daily_df['volume'].rolling(window=5).mean()
        daily_df['volume_ma20'] = daily_df['volume'].rolling(window=20).mean()
        
        # æŒ‰æ—¥æœŸå¤„ç†åˆ†é’Ÿæ•°æ®
        for date, day_data in minute_df.groupby('date'):
            if len(day_data) < 10:  # æ•°æ®å¤ªå°‘è·³è¿‡
                continue
                
            # è·å–å¯¹åº”æ—¥çº¿æ•°æ®
            daily_info = daily_df[daily_df['date'] == date]
            if daily_info.empty:
                continue
                
            daily_volume = daily_info['volume'].iloc[0]
            volume_ma20 = daily_info['volume_ma20'].iloc[0]
            
            if pd.isna(volume_ma20) or volume_ma20 == 0:
                continue
                
            # è®¡ç®—å¼€ç›˜é‡æ¯”ï¼ˆå‰30åˆ†é’Ÿï¼‰
            opening_data = day_data.head(6)  # 5åˆ†é’ŸKçº¿ï¼Œ6æ ¹çº¦30åˆ†é’Ÿ
            opening_volume = opening_data['volume'].sum()
            
            # ä¼°ç®—å¼€ç›˜é‡æ¯”ï¼ˆå¼€ç›˜30åˆ†é’Ÿæˆäº¤é‡ vs å†å²åŒæœŸå¹³å‡ï¼‰
            opening_ratio = (opening_volume * 8) / volume_ma20  # 8 = 240åˆ†é’Ÿ/30åˆ†é’Ÿ
            
            # è®¡ç®—æ—¥å†…é‡æ¯”å˜åŒ–
            day_data = day_data.copy()
            day_data['cumulative_volume'] = day_data['volume'].cumsum()
            day_data['time_progress'] = range(len(day_data))
            day_data['expected_volume'] = (day_data['time_progress'] + 1) / len(day_data) * daily_volume
            day_data['volume_ratio'] = day_data['cumulative_volume'] / day_data['expected_volume']
            
            # è¯†åˆ«æ”¾é‡æ—¶ç‚¹ï¼ˆé‡æ¯”çªç„¶å¢å¤§ï¼‰
            day_data['volume_spike'] = day_data['volume'] > day_data['volume'].rolling(window=3).mean() * 2
            surge_times = day_data[day_data['volume_spike']]['time'].tolist()
            
            # ä¿å­˜ç‰¹å¾
            features['opening_volume_ratio'].append({
                'date': date,
                'opening_ratio': opening_ratio,
                'opening_volume': opening_volume,
                'daily_volume': daily_volume
            })
            
            features['intraday_volume_patterns'].append({
                'date': date,
                'volume_ratios': day_data['volume_ratio'].tolist(),
                'times': day_data['time'].tolist()
            })
            
            features['volume_surge_times'].append({
                'date': date,
                'surge_times': surge_times,
                'surge_count': len(surge_times)
            })
            
            # è®¡ç®—æˆäº¤é‡åˆ†å¸ƒç‰¹å¾
            total_volume = day_data['volume'].sum()
            morning_volume = day_data[day_data['time'] <= '11:30:00']['volume'].sum()
            afternoon_volume = total_volume - morning_volume
            
            features['daily_volume_distribution'].append({
                'date': date,
                'morning_ratio': morning_volume / total_volume if total_volume > 0 else 0,
                'afternoon_ratio': afternoon_volume / total_volume if total_volume > 0 else 0,
                'total_volume': total_volume
            })
            
        return features
        
    def analyze_volume_patterns(self, features: Dict) -> Dict:
        """
        åˆ†æé‡æ¯”æ¨¡å¼ï¼Œè¯†åˆ«å¼‚å¸¸æ”¾é‡
        
        Args:
            features: calculate_volume_ratio_featuresè¿”å›çš„ç‰¹å¾å­—å…¸
            
        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        analysis = {
            'high_opening_ratio_days': [],  # å¼€ç›˜é«˜é‡æ¯”æ—¥æœŸ
            'intraday_surge_patterns': [],  # æ—¥å†…æ”¾é‡æ¨¡å¼
            'volume_distribution_analysis': {},  # æˆäº¤é‡åˆ†å¸ƒåˆ†æ
            'statistics': {}
        }
        
        # åˆ†æå¼€ç›˜é‡æ¯”
        opening_ratios = [item['opening_ratio'] for item in features['opening_volume_ratio']]
        if opening_ratios:
            ratio_mean = np.mean(opening_ratios)
            ratio_std = np.std(opening_ratios)
            threshold = ratio_mean + 1.5 * ratio_std
            
            for item in features['opening_volume_ratio']:
                if item['opening_ratio'] > threshold:
                    analysis['high_opening_ratio_days'].append({
                        'date': item['date'],
                        'opening_ratio': item['opening_ratio'],
                        'significance': (item['opening_ratio'] - ratio_mean) / ratio_std
                    })
        
        # åˆ†ææ—¥å†…æ”¾é‡æ¨¡å¼
        for item in features['volume_surge_times']:
            if item['surge_count'] >= 3:  # å¤šæ¬¡æ”¾é‡
                analysis['intraday_surge_patterns'].append({
                    'date': item['date'],
                    'surge_count': item['surge_count'],
                    'surge_times': item['surge_times']
                })
        
        # ç»Ÿè®¡ä¿¡æ¯
        analysis['statistics'] = {
            'total_days': len(features['opening_volume_ratio']),
            'high_opening_days': len(analysis['high_opening_ratio_days']),
            'surge_pattern_days': len(analysis['intraday_surge_patterns']),
            'avg_opening_ratio': np.mean(opening_ratios) if opening_ratios else 0
        }
        
        return analysis
        
    def plot_volume_analysis(self, features: Dict, analysis: Dict, save_path: str = None):
        """
        ç»˜åˆ¶é‡æ¯”åˆ†æå›¾è¡¨
        
        Args:
            features: é‡æ¯”ç‰¹å¾æ•°æ®
            analysis: åˆ†æç»“æœ
            save_path: ä¿å­˜è·¯å¾„
        """
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle(f'{self.stock_code} åˆ†é’Ÿçº§é‡æ¯”ç‰¹å¾åˆ†æ', fontsize=16, fontweight='bold')
        
        # 1. å¼€ç›˜é‡æ¯”æ—¶åºå›¾
        ax1 = axes[0, 0]
        opening_data = features['opening_volume_ratio']
        dates = [item['date'] for item in opening_data]
        ratios = [item['opening_ratio'] for item in opening_data]
        
        ax1.plot(dates, ratios, 'b-', alpha=0.7, linewidth=1)
        ax1.axhline(y=np.mean(ratios), color='r', linestyle='--', alpha=0.7, label=f'å‡å€¼: {np.mean(ratios):.2f}')
        
        # æ ‡è®°é«˜é‡æ¯”æ—¥æœŸ
        for item in analysis['high_opening_ratio_days']:
            ax1.scatter(item['date'], item['opening_ratio'], color='red', s=50, zorder=5)
            
        ax1.set_title('å¼€ç›˜é‡æ¯”æ—¶åº')
        ax1.set_ylabel('å¼€ç›˜é‡æ¯”')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # 2. å¼€ç›˜é‡æ¯”åˆ†å¸ƒç›´æ–¹å›¾
        ax2 = axes[0, 1]
        ax2.hist(ratios, bins=20, alpha=0.7, color='skyblue', edgecolor='black')
        ax2.axvline(x=np.mean(ratios), color='r', linestyle='--', label=f'å‡å€¼: {np.mean(ratios):.2f}')
        ax2.axvline(x=np.mean(ratios) + 1.5*np.std(ratios), color='orange', linestyle='--', 
                   label=f'å¼‚å¸¸é˜ˆå€¼: {np.mean(ratios) + 1.5*np.std(ratios):.2f}')
        ax2.set_title('å¼€ç›˜é‡æ¯”åˆ†å¸ƒ')
        ax2.set_xlabel('å¼€ç›˜é‡æ¯”')
        ax2.set_ylabel('é¢‘æ¬¡')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # 3. æ—¥å†…æ”¾é‡æ¬¡æ•°ç»Ÿè®¡
        ax3 = axes[1, 0]
        surge_counts = [item['surge_count'] for item in features['volume_surge_times']]
        surge_dates = [item['date'] for item in features['volume_surge_times']]
        
        colors = ['red' if count >= 3 else 'blue' for count in surge_counts]
        ax3.scatter(surge_dates, surge_counts, c=colors, alpha=0.6)
        ax3.axhline(y=3, color='orange', linestyle='--', alpha=0.7, label='å¤šæ¬¡æ”¾é‡é˜ˆå€¼')
        ax3.set_title('æ—¥å†…æ”¾é‡æ¬¡æ•°')
        ax3.set_ylabel('æ”¾é‡æ¬¡æ•°')
        ax3.legend()
        ax3.grid(True, alpha=0.3)
        
        # 4. ç»Ÿè®¡ä¿¡æ¯è¡¨æ ¼
        ax4 = axes[1, 1]
        ax4.axis('off')
        
        stats = analysis['statistics']
        stats_text = f"""
        åˆ†æç»Ÿè®¡ä¿¡æ¯:
        
        æ€»åˆ†æå¤©æ•°: {stats['total_days']}
        é«˜å¼€ç›˜é‡æ¯”å¤©æ•°: {stats['high_opening_days']}
        å¤šæ¬¡æ”¾é‡å¤©æ•°: {stats['surge_pattern_days']}
        å¹³å‡å¼€ç›˜é‡æ¯”: {stats['avg_opening_ratio']:.2f}
        
        å¼‚å¸¸æ”¾é‡æ¯”ä¾‹: {stats['high_opening_days']/stats['total_days']*100:.1f}%
        å¤šæ¬¡æ”¾é‡æ¯”ä¾‹: {stats['surge_pattern_days']/stats['total_days']*100:.1f}%
        """
        
        ax4.text(0.1, 0.9, stats_text, transform=ax4.transAxes, fontsize=12,
                verticalalignment='top', bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"å›¾è¡¨å·²ä¿å­˜è‡³: {save_path}")
        
        plt.show()
        
    def print_analysis_report(self, analysis: Dict):
        """æ‰“å°åˆ†ææŠ¥å‘Š"""
        print("\n" + "="*60)
        print(f"ğŸ“Š {self.stock_code} åˆ†é’Ÿçº§é‡æ¯”ç‰¹å¾åˆ†ææŠ¥å‘Š")
        print("="*60)
        
        stats = analysis['statistics']
        print(f"\nğŸ“ˆ åŸºç¡€ç»Ÿè®¡:")
        print(f"   æ€»åˆ†æå¤©æ•°: {stats['total_days']}")
        print(f"   å¹³å‡å¼€ç›˜é‡æ¯”: {stats['avg_opening_ratio']:.2f}")
        print(f"   é«˜å¼€ç›˜é‡æ¯”å¤©æ•°: {stats['high_opening_days']} ({stats['high_opening_days']/stats['total_days']*100:.1f}%)")
        print(f"   å¤šæ¬¡æ”¾é‡å¤©æ•°: {stats['surge_pattern_days']} ({stats['surge_pattern_days']/stats['total_days']*100:.1f}%)")
        
        print(f"\nğŸ”¥ å¼‚å¸¸å¼€ç›˜é‡æ¯”æ—¥æœŸ (å‰10ä¸ª):")
        high_days = sorted(analysis['high_opening_ratio_days'], 
                          key=lambda x: x['opening_ratio'], reverse=True)[:10]
        for item in high_days:
            print(f"   {item['date'].strftime('%Y-%m-%d')}: é‡æ¯” {item['opening_ratio']:.2f} "
                  f"(æ˜¾è‘—æ€§ {item['significance']:.1f}Ïƒ)")
        
        print(f"\nâš¡ æ—¥å†…å¤šæ¬¡æ”¾é‡æ¨¡å¼ (å‰5ä¸ª):")
        surge_days = sorted(analysis['intraday_surge_patterns'], 
                           key=lambda x: x['surge_count'], reverse=True)[:5]
        for item in surge_days:
            print(f"   {item['date'].strftime('%Y-%m-%d')}: {item['surge_count']}æ¬¡æ”¾é‡ "
                  f"æ—¶ç‚¹: {', '.join(item['surge_times'][:3])}")
        
        print("\n" + "="*60)


def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºåˆ†é’Ÿçº§é‡æ¯”åˆ†æ"""
    # åˆ†æå‚æ•°
    stock_code = "sz.000063"
    start_date = "2024-11-01"
    end_date = "2025-01-24"
    
    print(f"ğŸš€ å¼€å§‹åˆ†æ {stock_code} çš„åˆ†é’Ÿçº§é‡æ¯”ç‰¹å¾...")
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = MinuteVolumeAnalyzer(stock_code)
    
    # è·å–æ•°æ®
    print("\nğŸ“Š è·å–åˆ†é’Ÿå’Œæ—¥çº¿æ•°æ®...")
    minute_data = analyzer.fetch_minute_data(start_date, end_date, frequency="5")
    daily_data = analyzer.fetch_daily_data(start_date, end_date)
    
    if minute_data is None or daily_data is None:
        print("âŒ æ•°æ®è·å–å¤±è´¥")
        return
    
    # è®¡ç®—é‡æ¯”ç‰¹å¾
    print("\nğŸ” è®¡ç®—é‡æ¯”ç‰¹å¾...")
    features = analyzer.calculate_volume_ratio_features()
    
    if not features['opening_volume_ratio']:
        print("âŒ é‡æ¯”ç‰¹å¾è®¡ç®—å¤±è´¥")
        return
    
    # åˆ†æé‡æ¯”æ¨¡å¼
    print("\nğŸ“ˆ åˆ†æé‡æ¯”æ¨¡å¼...")
    analysis = analyzer.analyze_volume_patterns(features)
    
    # æ‰“å°æŠ¥å‘Š
    analyzer.print_analysis_report(analysis)
    
    # ç»˜åˆ¶å›¾è¡¨
    print("\nğŸ“Š ç”Ÿæˆåˆ†æå›¾è¡¨...")
    save_path = f"minute_volume_analysis_{stock_code.replace('.', '_')}.png"
    analyzer.plot_volume_analysis(features, analysis, save_path)
    
    print(f"\nâœ… åˆ†é’Ÿçº§é‡æ¯”åˆ†æå®Œæˆ!")
    
    return analyzer, features, analysis


if __name__ == "__main__":
    analyzer, features, analysis = main()